{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The SAFE Protocol\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This notebook illustrates a run of the SAFE Protocol described in {cite}`SAFE`. \n",
    "\n",
    "The Toy implementation of SAFE is merely illustrative-- mock data of a small size will be used to illustrate the basic mechanics of the SAFE protocol.\n",
    "\n",
    "### Setting Up Toy Implementation\n",
    "\n",
    "To illustrate how the SAFE Protocol works, we will mock the data of 5 users who contribute feature vectors. \n",
    "\n",
    "#### Set Up Raw Vector Creation\n",
    "\n",
    "First, let's create the raw feature vectors for each user. \n",
    "\n",
    "These vectors represent the raw data the SAFE protocol wants to keep private whilst allowing for useful computation over.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are is the feature vector for user 0: \n",
      "tensor([[0.4963],\n",
      "        [0.7682]])\n",
      "\n",
      "\n",
      "Here are is the feature vector for user 1: \n",
      "tensor([[0.0885],\n",
      "        [0.1320]])\n",
      "\n",
      "\n",
      "Here are is the feature vector for user 2: \n",
      "tensor([[0.3074],\n",
      "        [0.6341]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SET UP - Create raw feature vectors \n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "    # for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "    # CONSTANTS for a run of the Protocol\n",
    "NUMBER_OF_USERS = 3\n",
    "NUMBER_OF_FEATURES_PER_USER_VECTOR = 2\n",
    "VECTOR_SHAPE = (NUMBER_OF_FEATURES_PER_USER_VECTOR, 1)\n",
    "# TODO: actually, VECTOR_SHAPE is redundant. That wasn't the source of the error. But, anyways.\n",
    " \n",
    "raw_feature_vectors = {}\n",
    "\n",
    "for i in range(NUMBER_OF_USERS):\n",
    "    raw_feature_vectors[i] = torch.rand(VECTOR_SHAPE)\n",
    "    print(f\"Here are is the feature vector for user {i}: \")\n",
    "    print(raw_feature_vectors[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHARE CREATION AND DISTRIBUTION\n",
    "\n",
    "Next, each user will generate (N-1) shares from the interval [-D, D], where N is the number of users. \n",
    "\n",
    "Each share is a K-dimensional vector, where K is the number of features each user's raw feature vector has.\n",
    "\n",
    "Each user uses these N-1 shares to generate their own Nth share. \n",
    "\n",
    "Then, they will distribute the N-1 shares to the other N-1 users, whilst keeping their Nth share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the shares for each user \n",
      "\n",
      "Let's take a look at shares each user will distribute:\n",
      "\n",
      "User 0: \n",
      "\n",
      "tensor([[6.8884],\n",
      "        [5.1591]])\n",
      "tensor([[-1.5886],\n",
      "        [-4.8217]])\n",
      "\n",
      "\n",
      "And here's their Nth share:\n",
      "\n",
      "tensor([[-4.8036],\n",
      "        [ 0.4308]])\n",
      "\n",
      "\n",
      "User 1: \n",
      "\n",
      "tensor([[ 0.2255],\n",
      "        [-1.9013]])\n",
      "tensor([[ 5.6760],\n",
      "        [-3.9337]])\n",
      "\n",
      "\n",
      "And here's their Nth share:\n",
      "\n",
      "tensor([[-5.8130],\n",
      "        [ 5.9671]])\n",
      "\n",
      "\n",
      "User 2: \n",
      "\n",
      "tensor([[-0.4681],\n",
      "        [ 1.6676]])\n",
      "tensor([[8.1623],\n",
      "        [0.0937]])\n",
      "\n",
      "\n",
      "And here's their Nth share:\n",
      "\n",
      "tensor([[-7.3868],\n",
      "        [-1.1273]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SHARE CREATION\n",
    "\n",
    "import random\n",
    "# TODO - change this to secret.\n",
    "from token import NUMBER\n",
    "from unicodedata import name\n",
    "\n",
    "from numpy import shares_memory \n",
    "random.seed(0)\n",
    "\n",
    "D_VALUE = 10.0 # defining the interval from which users drawn random share vectors.\n",
    "\n",
    "print(\"Generating the shares for each user \\n\")\n",
    "each_users_shares_to_distribute = {} # mapping from i to list of tensors.\n",
    "each_users_Nth_share = {} # mapping from i to 4-D tensor\n",
    "for user in range(NUMBER_OF_USERS):\n",
    "    # Each user first generates N-1 shares : a share to be sent to every other user.\n",
    "    each_users_shares_to_distribute[user] = []\n",
    "    for other_user in range(NUMBER_OF_USERS - 1):\n",
    "        share_to_distribute = [random.uniform(-D_VALUE, D_VALUE) for i in range(NUMBER_OF_FEATURES_PER_USER_VECTOR)]\n",
    "        share_to_distribute = torch.reshape(torch.tensor(share_to_distribute), VECTOR_SHAPE)\n",
    "        each_users_shares_to_distribute[user].append(share_to_distribute)\n",
    "    # Then, each user calculates their own Nth share from the N-1 Shares the draw from the interval\n",
    "    sum_of_shares = torch.zeros(VECTOR_SHAPE)\n",
    "    for share in each_users_shares_to_distribute[user]:\n",
    "        sum_of_shares.add_(share)\n",
    "    # print(f\"Here is user_{user}'s sum of shares: {sum_of_shares}\")\n",
    "    each_users_Nth_share[user] = raw_feature_vectors[user] - sum_of_shares \n",
    "\"\"\"\n",
    "TODO:\n",
    "Not sure whether there's a better way to generate the shares. The calls to the random.uniform() method for each share vector value seems sub-optimal but I can't quite find an 'off-the-shelf' method that generates the matrix/dictionary more easily. This triple nested loop is not computationally efficient. Is commenting on the algorithm's time complexity worth doing?\n",
    "\n",
    "TODO: \n",
    "Also not sure whether the 'random' provided by Python is sufficiently random. Or whether the presence of a 'seed' value complicates things.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Let's take a look at shares each user will distribute:\\n\")\n",
    "for user in range(NUMBER_OF_USERS):\n",
    "    print(f\"User {user}: \\n\")\n",
    "    for share in each_users_shares_to_distribute[user]:\n",
    "        print(share)\n",
    "    print(\"\\n\")    \n",
    "    print(\"And here's their Nth share:\\n\")\n",
    "    print(each_users_Nth_share[user])\n",
    "    print(\"\\n\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's distribute the shares among the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributing shares...\n",
      "\n",
      "Let's see what the first three users got:\n",
      "User_0 received:\n",
      "tensor([[ 0.2255],\n",
      "        [-1.9013]])\n",
      "tensor([[-0.4681],\n",
      "        [ 1.6676]])\n",
      "\n",
      "\n",
      "User_1 received:\n",
      "tensor([[6.8884],\n",
      "        [5.1591]])\n",
      "tensor([[8.1623],\n",
      "        [0.0937]])\n",
      "\n",
      "\n",
      "User_2 received:\n",
      "tensor([[-1.5886],\n",
      "        [-4.8217]])\n",
      "tensor([[ 5.6760],\n",
      "        [-3.9337]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SHARE Distribution\n",
    "\n",
    "print(\"Distributing shares...\\n\")\n",
    "each_users_received_shares = {}\n",
    "# set up the map\n",
    "for i in range(NUMBER_OF_USERS):\n",
    "    each_users_received_shares[i] = []\n",
    "# fill the map\n",
    "for user in range(NUMBER_OF_USERS):\n",
    "    other_user_ids = [ind for ind in range(NUMBER_OF_USERS) if ind != user]\n",
    "    # get the shares for user_0 to send to other users\n",
    "    shares_to_send = [share for share in each_users_shares_to_distribute[user]]\n",
    "    for other_user, share_to_send in zip(other_user_ids, shares_to_send):\n",
    "        each_users_received_shares[other_user].append(share_to_send)\n",
    "# TODO - add a more robust sanity check to ensure shares were sent.\n",
    "print(\"Let's see what the first three users got:\")\n",
    "for i in range(3):\n",
    "    print(f\"User_{i} received:\")\n",
    "    print(*each_users_received_shares[i], sep=\"\\n\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# sanity check\n",
    "assert len(each_users_received_shares[0]) == NUMBER_OF_USERS - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obfuscated Vector Generation\n",
    "\n",
    "Each user can now calculate their own ofuscated feature vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's what each user will send to the aggregator:\n",
      "\n",
      "User 0:\n",
      "tensor([[-5.0462],\n",
      "        [ 0.1971]])\n",
      "\n",
      "\n",
      "User 1:\n",
      "tensor([[ 9.2377],\n",
      "        [11.2199]])\n",
      "\n",
      "\n",
      "User 2:\n",
      "tensor([[-3.2994],\n",
      "        [-9.8827]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GENERATING OBFUSCATED FEATURE Vectors:\n",
    "\"\"\"\n",
    "each_users_masked_vector = {}\n",
    "\n",
    "for user in range(NUMBER_OF_USERS):\n",
    "    sum_of_received_shares = torch.zeros(VECTOR_SHAPE)\n",
    "    for share in each_users_received_shares[user]:\n",
    "        sum_of_received_shares.add_(share)\n",
    "    each_users_masked_vector[user] = each_users_Nth_share[user] + sum_of_received_shares \n",
    "\n",
    "print(\"Here's what each user will send to the aggregator:\\n\")\n",
    "for user, masked_vector in each_users_masked_vector.items():\n",
    "    print(f\"User {user}:\")\n",
    "    print(masked_vector)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating Feature Vectors\n",
    "\n",
    "Now we will mock an aggregator who receives each feature vector and computes a target function. In the actual protocol, each user would 'send' their masked vector to an aggregator. For simplicity's sake, we will simply act as an aggregator that has already received these vectors, and simply compute the target function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of masked vectors: \n",
      "\n",
      " tensor([[0.8922],\n",
      "        [1.5343]])\n",
      "\n",
      "Sum of raw vectors: \n",
      "\n",
      " tensor([[0.8922],\n",
      "        [1.5343]])\n"
     ]
    }
   ],
   "source": [
    "# Computing Target Function: Aggregate Sum\n",
    "\n",
    "target_result = sum(raw_feature_vectors[user] for user in raw_feature_vectors.keys())\n",
    "\n",
    "masked_vector_result = sum(each_users_masked_vector[user] for user in each_users_masked_vector.keys())\n",
    "\n",
    "print(f\"Sum of masked vectors: \\n\\n {masked_vector_result}\\n\")\n",
    "print(f\"Sum of raw vectors: \\n\\n {target_result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility of Protocol\n",
    "\n",
    "As the output from the code block above shows, the aggregate sum of the masked vectors is equivalent to the aggregate sum of the raw vectors of the users. \n",
    "\n",
    "Also, it follows from this that simple mean of both vector sets are equal as well. \n",
    "\n",
    "SAFE thus does allow one to compute some aggregate functions over user data without having direct access to the user data. \n",
    "\n",
    "However, let us now consider how robustly it masks the raw feature vectors from potential adversaries who would try to infer things about the raw data from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliography\n",
    "\n",
    "[needed to include this bibliography tag to get citations to work: found that from https://github.com/executablebooks/jupyter-book/issues/1662]:# (why this bibliography code block is needed)\n",
    "\n",
    "```{bibliography}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('my_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca44cade67de28f420a60dffa446fdd52df8cf85741523fb65df66df28ddc7a0"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
