{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The SAFE Protocol\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This notebook illustrates a run of the SAFE Protocol described in (1). \n",
    "\n",
    "SAFE is a protocol that allows for the secure aggregation of $N>1$ feature vectors in a semi-honest security model.\n",
    "\n",
    "The Toy implementation of SAFE is merely illustrative-- mock data of a small size will be used to illustrate the basic mechanics of the SAFE protocol.\n",
    "\n",
    "**n.b.** The code implementation in this notebook can be improved-- for instance, it would be preferable to implement the protocol in an *object-oriented* manner for code that is less visually noisy. However, to illustrate the inner workings of each step of the protocol more clearly, I opt for a procedural approach. See [the notebook where I apply the protocol to the use case for an object-oriented implementation](safe-applied-to-use-case.ipynb)\n",
    "\n",
    "### Setting Up Toy Implementation\n",
    "\n",
    "To illustrate how the SAFE Protocol works, we will mock the data of 3 users who contribute feature vectors. \n",
    "\n",
    "#### Set Up Raw Vector Creation\n",
    "\n",
    "First, let's create the raw feature vectors for each user. \n",
    "\n",
    "These vectors represent distributions of the raw data the SAFE protocol wants to keep private whilst allowing for useful computation over.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the feature vector for user 0: \n",
      "tensor([[0.4963],\n",
      "        [0.7682]])\n",
      "\n",
      "\n",
      "Here is the feature vector for user 1: \n",
      "tensor([[0.0885],\n",
      "        [0.1320]])\n",
      "\n",
      "\n",
      "Here is the feature vector for user 2: \n",
      "tensor([[0.3074],\n",
      "        [0.6341]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SET UP - Create raw feature vectors \n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "# for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "NUMBER_OF_USERS = 3\n",
    "NUMBER_OF_FEATURES_PER_USER_VECTOR = 2\n",
    "VECTOR_SHAPE = (NUMBER_OF_FEATURES_PER_USER_VECTOR, 1)\n",
    " \n",
    "raw_feature_vectors = {}\n",
    "\n",
    "for i in range(NUMBER_OF_USERS):\n",
    "    raw_feature_vectors[i] = torch.rand(VECTOR_SHAPE)\n",
    "    print(f\"Here is the feature vector for user {i}: \")\n",
    "    print(raw_feature_vectors[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHARE CREATION AND DISTRIBUTION\n",
    "\n",
    "Next, each user will generate (N-1) shares from the interval [-D, D], where N is the number of users. \n",
    "\n",
    "Each share is a K-dimensional vector, where K is the number of features each user's raw feature vector has.\n",
    "\n",
    "Each user uses these N-1 shares to generate their own Nth share. \n",
    "\n",
    "Then, they will distribute the N-1 shares to the other N-1 users, whilst keeping their Nth share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the shares for each user \n",
      "\n",
      "Let's take a look at shares each user will distribute:\n",
      "\n",
      "User 0: \n",
      "\n",
      "tensor([[6.8884],\n",
      "        [5.1591]])\n",
      "tensor([[-1.5886],\n",
      "        [-4.8217]])\n",
      "\n",
      "\n",
      "And here's their Nth share:\n",
      "\n",
      "tensor([[-4.8036],\n",
      "        [ 0.4308]])\n",
      "\n",
      "\n",
      "User 1: \n",
      "\n",
      "tensor([[ 0.2255],\n",
      "        [-1.9013]])\n",
      "tensor([[ 5.6760],\n",
      "        [-3.9337]])\n",
      "\n",
      "\n",
      "And here's their Nth share:\n",
      "\n",
      "tensor([[-5.8130],\n",
      "        [ 5.9671]])\n",
      "\n",
      "\n",
      "User 2: \n",
      "\n",
      "tensor([[-0.4681],\n",
      "        [ 1.6676]])\n",
      "tensor([[8.1623],\n",
      "        [0.0937]])\n",
      "\n",
      "\n",
      "And here's their Nth share:\n",
      "\n",
      "tensor([[-7.3868],\n",
      "        [-1.1273]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SHARE CREATION\n",
    "\n",
    "import random\n",
    "from token import NUMBER\n",
    "from unicodedata import name\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "D_VALUE = 10.0 # defining the interval from which users drawn random share vectors.\n",
    "\n",
    "print(\"Generating the shares for each user \\n\")\n",
    "each_users_shares_to_distribute = {} # mapping from i to list of tensors.\n",
    "each_users_Nth_share = {} # mapping from i to 4-D tensor\n",
    "for user in range(NUMBER_OF_USERS):\n",
    "    # Each user first generates N-1 shares : a share to be sent to every other user.\n",
    "    each_users_shares_to_distribute[user] = []\n",
    "    for other_user in range(NUMBER_OF_USERS - 1):\n",
    "        share_to_distribute = [random.uniform(-D_VALUE, D_VALUE) for i in range(NUMBER_OF_FEATURES_PER_USER_VECTOR)]\n",
    "        share_to_distribute = torch.reshape(torch.tensor(share_to_distribute), VECTOR_SHAPE)\n",
    "        each_users_shares_to_distribute[user].append(share_to_distribute)\n",
    "    # Then, each user calculates their own Nth share from the N-1 Shares the draw from the interval\n",
    "    sum_of_shares = torch.zeros(VECTOR_SHAPE)\n",
    "    for share in each_users_shares_to_distribute[user]:\n",
    "        sum_of_shares.add_(share)\n",
    "    each_users_Nth_share[user] = raw_feature_vectors[user] - sum_of_shares \n",
    "\n",
    "print(\"Let's take a look at shares each user will distribute:\\n\")\n",
    "for user in range(NUMBER_OF_USERS):\n",
    "    print(f\"User {user}: \\n\")\n",
    "    for share in each_users_shares_to_distribute[user]:\n",
    "        print(share)\n",
    "    print(\"\\n\")    \n",
    "    print(\"And here's their Nth share:\\n\")\n",
    "    print(each_users_Nth_share[user])\n",
    "    print(\"\\n\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's distribute the shares among the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributing shares...\n",
      "\n",
      "Let's see what the first three users got:\n",
      "User_0 received:\n",
      "tensor([[ 0.2255],\n",
      "        [-1.9013]])\n",
      "tensor([[-0.4681],\n",
      "        [ 1.6676]])\n",
      "\n",
      "\n",
      "User_1 received:\n",
      "tensor([[6.8884],\n",
      "        [5.1591]])\n",
      "tensor([[8.1623],\n",
      "        [0.0937]])\n",
      "\n",
      "\n",
      "User_2 received:\n",
      "tensor([[-1.5886],\n",
      "        [-4.8217]])\n",
      "tensor([[ 5.6760],\n",
      "        [-3.9337]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SHARE Distribution\n",
    "\n",
    "print(\"Distributing shares...\\n\")\n",
    "each_users_received_shares = {}\n",
    "# set up the map\n",
    "for i in range(NUMBER_OF_USERS):\n",
    "    each_users_received_shares[i] = []\n",
    "# fill the map\n",
    "for user in range(NUMBER_OF_USERS):\n",
    "    other_user_ids = [ind for ind in range(NUMBER_OF_USERS) if ind != user]\n",
    "    # get the shares for user_0 to send to other users\n",
    "    shares_to_send = [share for share in each_users_shares_to_distribute[user]]\n",
    "    for other_user, share_to_send in zip(other_user_ids, shares_to_send):\n",
    "        each_users_received_shares[other_user].append(share_to_send)\n",
    "print(\"Let's see what the first three users got:\")\n",
    "for i in range(3):\n",
    "    print(f\"User_{i} received:\")\n",
    "    print(*each_users_received_shares[i], sep=\"\\n\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# sanity check\n",
    "assert len(each_users_received_shares[0]) == NUMBER_OF_USERS - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obfuscated Vector Generation\n",
    "\n",
    "Each user can now calculate their own ofuscated feature vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's what each user will send to the aggregator:\n",
      "\n",
      "User 0:\n",
      "tensor([[-5.0462],\n",
      "        [ 0.1971]])\n",
      "\n",
      "\n",
      "User 1:\n",
      "tensor([[ 9.2377],\n",
      "        [11.2199]])\n",
      "\n",
      "\n",
      "User 2:\n",
      "tensor([[-3.2994],\n",
      "        [-9.8827]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GENERATING OBFUSCATED FEATURE Vectors:\n",
    "\"\"\"\n",
    "each_users_masked_vector = {}\n",
    "\n",
    "for user in range(NUMBER_OF_USERS):\n",
    "    sum_of_received_shares = torch.zeros(VECTOR_SHAPE)\n",
    "    for share in each_users_received_shares[user]:\n",
    "        sum_of_received_shares.add_(share)\n",
    "    each_users_masked_vector[user] = each_users_Nth_share[user] + sum_of_received_shares \n",
    "\n",
    "print(\"Here's what each user will send to the aggregator:\\n\")\n",
    "for user, masked_vector in each_users_masked_vector.items():\n",
    "    print(f\"User {user}:\")\n",
    "    print(masked_vector)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating Feature Vectors\n",
    "\n",
    "Now we will mock an aggregator who receives each feature vector and computes a target function. In the actual protocol, each user would 'send' their masked vector to an aggregator. For simplicity's sake, we will simply act as an aggregator that has already received these vectors, and simply compute the target function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of masked vectors: \n",
      "\n",
      " tensor([[0.8922],\n",
      "        [1.5343]])\n",
      "\n",
      "Sum of raw vectors: \n",
      "\n",
      " tensor([[0.8922],\n",
      "        [1.5343]])\n"
     ]
    }
   ],
   "source": [
    "# Computing Target Function: Aggregate Sum\n",
    "\n",
    "target_result = sum(raw_feature_vectors[user] for user in raw_feature_vectors.keys())\n",
    "\n",
    "masked_vector_result = sum(each_users_masked_vector[user] for user in each_users_masked_vector.keys())\n",
    "\n",
    "print(f\"Sum of masked vectors: \\n\\n {masked_vector_result}\\n\")\n",
    "print(f\"Sum of raw vectors: \\n\\n {target_result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility of Protocol\n",
    "\n",
    "As the output from the code block above shows, the aggregate sum of the masked vectors is equivalent to the aggregate sum of the raw vectors of the users. \n",
    "\n",
    "Also, it follows from this that simple mean of both vector sets are equal as well. \n",
    "\n",
    "SAFE thus does allow one to compute aggregate functions over user data without having direct access to the user data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliography\n",
    "\n",
    "(1) Chaulwar A, Huth M. Secure Bayesian Federated Analytics for Privacy-Preserving Trend Detection. 2021; https://arxiv.org/abs/2107.13640."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-venv",
   "language": "python",
   "name": "project-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca44cade67de28f420a60dffa446fdd52df8cf85741523fb65df66df28ddc7a0"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
