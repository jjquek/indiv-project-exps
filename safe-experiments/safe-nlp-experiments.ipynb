{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAFE Protocol NLP Experiments \n",
    "\n",
    "[update the other Jupyter files to account for two notebooks]:# (directory-integration)\n",
    "\n",
    "[look at this link: https://medium.com/codex/the-magical-markdown-i-bet-you-dont-know-b51f8c049773]:# (resource for markdown)\n",
    "\n",
    "This notebook contains the following contents:\n",
    "* [Section 1: Introduction](#introduction)\n",
    "* [Section 2: Prior Calculation](#prior-calculation)\n",
    "* [Section 3: Likelihood Calculation](#likelihood-calculation-a-classanchor-idlikelihooda)\n",
    "\n",
    "It builds on top of [the other notebook where I illustrated the bare SAFE Protocol itself as well as some extensions to make it more secure](/safe-experiments.ipynb). This notebook specifically illustrates the application of SAFE to trend detection in document interactions.\n",
    "\n",
    "### Introduction <a class=\"anchor\" id=\"introduction\"></a>\n",
    "\n",
    "##### What Trends In Documents Are\n",
    "\n",
    "Huth and Chaulwar offer the following definition of a trend for interacted documents in their paper (Huth, Chaulwar, 4),\n",
    "\n",
    "[add proper citation]:# (citation)\n",
    "\n",
    ">\"Keywords that are not frequently present in past interacted documents but that appear frequently in current interacted documents\"\n",
    "\n",
    "They note that the definition is \"very basic\". However, it suffices as a definition to illustrate how their Bayesian approach to federated analytics.\n",
    "\n",
    "[look into seasonality]: # (extra-bit)\n",
    "\n",
    "##### Formal Specification of The Task\n",
    "\n",
    "The terminology and description in this section is also taken from the paper. \n",
    "\n",
    "Key Terms:\n",
    "* $D$ - Document Set \n",
    "* $t$ - Trending Keyword\n",
    "* $V$ - Set of possible trending keywords in $D$\n",
    "* $D_i$ - subset of $D$ that $user_i$ has interacted with\n",
    "\n",
    "[add proper citation]:# (citation)\n",
    "\n",
    "The aim is to determine a distribution $p(t | D)$ that specifies a probability for a keyword in $V$ being trending. \n",
    "\n",
    "Using Bayes formula, the task can be phrased as the determinination for each term $t_i$ in $V$:\n",
    "\n",
    "$$\n",
    "    p(t_i = t | D) = \\frac{P(D | t_i = t)p(t_i = t)}{p(D)}\n",
    "$$\n",
    "\n",
    "* Application To Use Case\n",
    "\n",
    "[one issue of relating the use case to the trend detection methodology is that in the specific case mentioned in the paper, 'multiple users can interact with (the) same document' (4), however, this wouldn't make sense in our case?]:# (question-to-resolve)\n",
    "\n",
    "### Prior Calculation <a class=\"anchor\" id=\"prior-calculation\"></a>\n",
    "\n",
    "Here we are interested in calculating the term $p(t_i = t)$, the prior discrete probablity for a keyword in $V$ for being a trending keyword.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run code generating loading in/creating the data & generating the prior distribution\n",
    "\n",
    "'''\n",
    "prior distribution is modelled as a Dirichlet distribution parametized by the IDF of keywords in V\n",
    "- generate IDF of keywords in V\n",
    "- construct Dirichlet distribution using generated IDF as arg.\n",
    "\n",
    "running it iteratively: start with uniform priors,\n",
    "\n",
    "TODO - how do we update uniform priors over each distribution? -- assigning the result of each round as the new IDF parameter?\n",
    "\n",
    "can use tensorflow's probability library to generate the Dirichlet distribution.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood Calculation <a class=\"anchor\" id=\"likelihood\"></a>\n",
    "\n",
    "Each user has their own subset of the document set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Describing the use case:\n",
    "\n",
    "3 users, they use the app for a month, once a day, 5 days a week. \n",
    "\n",
    "Every day, they answer a question, \"How are you feeling today?\"-- \n",
    "\n",
    "The answers given are something like,\n",
    "\n",
    "\"I felt joy\"\n",
    "\"I felt anger\"\n",
    "\"I felt fear\"\n",
    "\"I felt sadness\"\n",
    "\"I felt digust\"\n",
    "\"I felt surpise\"\n",
    "\n",
    " Ekman 1992a:\n",
    "\n",
    "(joy, anger, fear, sadness, disgust, and surprise). <= not very interesting.\n",
    "\n",
    "What about...\n",
    "\n",
    "And then they are prompted to journal in response to a follow-up question, \"Why did you feel that way?\". NOTE: sentiment analysis is kind of redundant... here. They've already indicated what they feel.\n",
    "\n",
    "These responses are stored in a list over the period of two weeks. (That's their own Di which we want to keep private).\n",
    "\n",
    "So, SAFE will help us to track, what emotions have people started to feel over time.\n",
    "\n",
    "METRICS:\n",
    "- count: how many people felt X over the 2 week period?\n",
    "- simple mean: what's the average number of people that felt X over a 4 month period?\n",
    "\n",
    "# TODO - feels like the use case doesn't make for very interesting extensions...\n",
    "\n",
    "# NOTE : extending the use case: something similar to what is tracked. Now trying to track what resources are being accessed within the app, so to keywords are now not emotions but general topics.\n",
    "\n",
    "# thinking through some of the extensions :(e.g. weighted mean)\n",
    "thoughts on weighted mean:\n",
    "- each obfuscated feature vector is sent with a weight.\n",
    "- how secure would this be? Well, it would reveal : e.g., that the user has been accessing a lot of articles. (even though it's not clear which articles)...But, then, if it turns out that a particular topic/emotion has been 'trending', wouldn't that reveal a bit much about those who had heavier weights?\n",
    "\n",
    "The Bayesian FA that uses SAFE would help us to compute : what's the probability of each keyword (emotion) being trending (i.e., felt more now than in past sessions)\n",
    "\n",
    "'''\n",
    "\n",
    "# NOTE: maybe a good dataset to use would be GoEmotion? That's a large dataset that's been benchmarked academically.\n",
    "\n",
    "# step : Define D-- overall document set. \n",
    "\n",
    "# TODO - what are the document sets in this context? Would it be journal entries? \n",
    "''' \n",
    "Let's start with something simpler: let's say the document set is a set of possible answers to 'survey' like questions. For instance,\n",
    "\n",
    "# NOTE:  base this on the emotion taxonomy mentioned in GoEmotion.\n",
    "responses = [\n",
    "    u'I was upset today',\n",
    "    u'I was ...',\n",
    "] <= this list contains all the responses from each user. \n",
    "\n",
    "And then each user's D_i is the specific responses they clicked?\n",
    "\n",
    "And would the keywords be the emotions?\n",
    "'''\n",
    "# NOTE : if this is right, then there's no need for conference resolution? \n",
    "# TODO : are the only pre-processing steps necessary the keyword set calculation and the document frequency calculation in this particular use case?\n",
    "# NOTE : c.f. the PyTorch Deep Dive into NLP slides for methods that do the pre-processing for you.\n",
    "\n",
    "# D has a set of keywords, V, which are trending.\n",
    "\n",
    "# TODO - are the keywords the emotions? And then isn't there a low amount of keywords in V?\n",
    "\n",
    "# step: Each user's document sets are their answers.\n",
    "\n",
    "# TODO - what is p(D_i | t)?\n",
    "\n",
    "# Wouldn't it be fairly straightword? e.g. given that 'joy' is trending, wouldn't it be the case that the document set would largely consists of the 'I have been feeling joyful' today?\n",
    "\n",
    "# NOTE : comparing by ranking based on total count or pooled trend seems to be pretty easy to do...\n",
    "\n",
    "# TODO - get clear : why is a Dirichlet distribution used?\n",
    "\n",
    "# TODO - updating uniform priors iteratively\n",
    "\n",
    "'''\n",
    "Does that involve setting the p(t | D) that we get at one end of the result to be the new parameters for the dirichlet distribution used for the next round's priors?\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# todo - take from this example code block things which would be helpful to use\n",
    "\n",
    "# Rangarajan Krishnamoorthy, 2/2/2019\n",
    "# Using neuralcoref for coreference resolution\n",
    "\n",
    "taken from: https://www.rangakrish.com/index.php/2019/02/03/coreference-resolution-using-spacy/\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_coref_lg') # TODO : see if the large coref model is the right choice.\n",
    "\n",
    "examples = [\n",
    "    u'My sister has a dog and she loves him.',\n",
    "    u'My sister has a dog and she loves him. He is cute.',\n",
    "    u'My sister has a dog and she loves her.',\n",
    "    u'My brother has a dog and he loves her.',\n",
    "    u'Mary and Julie are sisters. They love chocolates.',\n",
    "    u'John and Mary are neighbours. She admires him because he works hard.',\n",
    "    u'X and Y are neighbours. She admires him because he works hard.',\n",
    "    u'The dog chased the cat. But it escaped.',\n",
    "]\n",
    "\n",
    "def printMentions(doc):\n",
    "    print '\\nAll the \"mentions\" in the given text:'\n",
    "    for cluster in doc._.coref_clusters:\n",
    "        print cluster.mentions\n",
    "\n",
    "def printPronounReferences(doc):\n",
    "    print '\\nPronouns and their references:'\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'PRON' and token._.in_coref:\n",
    "            for cluster in token._.coref_clusters:\n",
    "                print token.text + \" => \" + cluster.main.text\n",
    "\n",
    "def processDoc(text):\n",
    "    doc = nlp(text)\n",
    "    if doc._.has_coref:\n",
    "        print \"Given text: \" + text\n",
    "        printMentions(doc)\n",
    "        printPronounReferences(doc)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processDoc(examples[8])\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('my_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca44cade67de28f420a60dffa446fdd52df8cf85741523fb65df66df28ddc7a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
