{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAFE Protocol NLP Experiments \n",
    "\n",
    "[look at this link: https://medium.com/codex/the-magical-markdown-i-bet-you-dont-know-b51f8c049773]:# (resource for markdown)\n",
    "\n",
    "This notebook contains the following contents:\n",
    "\n",
    "\n",
    "It builds on top of the other notebook where I [illustrated the bare SAFE Protocol itself](./safe-illustration.ipynb) as well as [some suggestions to make it more secure](./safe-improved.ipynb). This notebook specifically illustrates the application of SAFE to trend detection in document interactions.\n",
    "\n",
    "As with the other notebooks, much of the material here relies heavily on {cite}`SAFE`.\n",
    "\n",
    "See Section 3.4.1 of the report for elaboration on the approach being implemented here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trending Mood Detection For Survey Responses\n",
    "\n",
    "As described in the report, users respond to a prompt question like \"*How do you feel today?*\" every day for a month, and an analysis on what responses are trending is carried out every 2 weeks.\n",
    "\n",
    "When submitting a response to this question, the user picks from a pre-defined list of responses that contains strings like the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_responses = {\n",
    "    0: \"I'm feeling joyful!\",\n",
    "    1: \"I'm feeling angry\",\n",
    "    2: \"I'm feeling disgusted\",\n",
    "    3: \"I'm feeling fearful\",\n",
    "    4: \"I'm feeling sad...\",\n",
    "    5: \"I'm feeling surprised!\",\n",
    "    6: \"I'm feeling neutral\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These responses are each encoded as numbers, such that what is actually stored locally on user devices as their responses are integers from `0` to `6` corresponding to each of these answers (`0` corresponds to `I'm feeling joyful!\"`, `1` corresponds to `\"I'm feeling angry\"`, and so on...)\n",
    "\n",
    "The target computation of the Bayesian approach to secure trend detection is:\n",
    "\n",
    "$$\n",
    "p(\\text{t} \\space =\\space t|D)= \\frac {p(D|\\text{t} \\space =\\space t|)p(\\text{t} \\space =\\space t|)}{p(D)} \n",
    "$$\n",
    "\n",
    "where $t$ is some term in the keyword set $V$. \n",
    "\n",
    "The **keyword set** $V$ for our experimental setting consists of the responses themselves, since what we what to determine is a probability distribution for the various moods given the overall document set contributed by users.\n",
    "\n",
    "As discussed in their paper, calculating the marginal probablity $p(D)$ would not be privacy-preserving. The authors advise avoiding calculating it by treating it as constant. Then, the posterior likelihood $p(\\text{t} \\space =\\space t|D)$ is proportional to ${p(D|\\text{t} \\space =\\space t|)p(\\text{t} \\space =\\space t|)}$. Since we are only trying to find trending keywords (in terms of rankings), we do not need the exact value of the posterior and we can simply consider this equation:\n",
    "\n",
    "$$\n",
    "p(\\text{t} \\space =\\space t|D) \\propto {p(D|\\text{t} \\space =\\space t|)p(\\text{t} \\space =\\space t|)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Defining Our Terms\n",
    "\n",
    "In particular, we want to define the terms on the RHS : the likelihood, $p(D|\\text{t} \\space =\\space t|)$, and the prior $p(\\text{t} \\space =\\space t|)$.\n",
    "\n",
    "##### Defining The Prior\n",
    "\n",
    "For the first run of the protocol, the priors will be defined uniformly-- i.e., $\\frac{1}{d}$ where $d$ is the number of keywords in $V$.\n",
    "\n",
    "For each subsequent run, the priors will be defined according to last round's posterior probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining the Likelihood Vector\n",
    "\n",
    "Let's suppose there are $N$ users who respond to the prompt question every day for $y$ days. (We assume that users respond every day with some response)\n",
    "\n",
    "This will mean that each user has a list of $y$ integer responses that represents the option they picked for each day. \n",
    "\n",
    "This will constitute their **document set** $D_{i}$ which we wish remains private, where *each integer* (representing a response) is a **document**.\n",
    "\n",
    "Each document's **primary keyword set** is simply a single-element set with the integer that represents the response they picked. (e.g. the primary keyword set of the document `1` just is `1`).\n",
    "\n",
    "As described in the paper, what ends up being the user's raw feature vector is a vector of likelihoods,\n",
    "\n",
    "$$\n",
    "L_{i}  =(p( D_ {i}  |\\text{t} \\space =\\space t_ {1}  ), \\cdots  ,p(  D_ {i}  |\\text{t} \\space =\\space t_ {d}  ))\n",
    "$$\n",
    "\n",
    "where $d$ is the number of words in the vocabulary $V$, and each $p(D_{i} | \\text{t} \\space =\\space t)$ is calculated by the fraction of the given keyword in the document set of the user.\n",
    "\n",
    "For instance, say that a user has the following document set of just 7 responses (for simplicity):\n",
    "\n",
    "```\n",
    "u_1 = [0, 1, 2, ,3, 1, 4, 5]  \n",
    "```\n",
    "\n",
    "They have 7 documents in total. Their feature vector of likelihoods is\n",
    "\n",
    "```\n",
    "V = [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "u_1 = [0, 1, 2, 3, 1, 4, 5]  \n",
    "\n",
    "u_1_feature_vector = [1/7, 2/7, 1/7, 1/7, 1/7,  1/7, 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing The Target Function\n",
    "\n",
    "Treating each user's document set $D_i$ as a random variable for the subset of the overall document set $D$ (i.e., the set of all user responses), then we can treat the aggregation of these instances (i.e., the likelihood of the whole document set) can be represented as the mean. (ibid., 5)\n",
    "\n",
    "So, the aggregator wants to compute the following for each keyword.\n",
    "\n",
    "$$\n",
    "p(D | \\text{t} \\space =\\space t_1) = \\sum_{i = 1}^N {p(D|\\text{t} \\space =\\space t_1|)}\n",
    "$$\n",
    "\n",
    "Aggregating the feature vectors for all users can be done securely using the SAFE Protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run : With Raw SAFE version\n",
    "\n",
    "#### Generating The Raw Feature Vectors\n",
    "\n",
    "Let's say there are 10 users who respond to the prompt question every day for 21 days, and as analysts we want to consider what responses are trending given this period.\n",
    "\n",
    "First, lets do a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as r\n",
    "from itertools import repeat\n",
    "from collections import Counter\n",
    "from MoodAppUser import MoodAppUser\n",
    "\n",
    "r.seed(123) # for reproducibility \n",
    "\n",
    "# as from above: \n",
    "POSSIBLE_RESPONSES = {\n",
    "    0: \"I'm feeling joyful!\",\n",
    "    1: \"I'm feeling angry\",\n",
    "    2: \"I'm feeling disgusted\",\n",
    "    3: \"I'm feeling fearful\",\n",
    "    4: \"I'm feeling sad...\",\n",
    "    5: \"I'm feeling surprised!\",\n",
    "    6: \"I'm feeling neutral\",\n",
    "}\n",
    "\n",
    "# e.g. SANITY CHECK\n",
    "KEYWORDS = [0, 1, 2, 3, 4, 5, 6] # corresponding to our 7-emotion taxonomy\n",
    "user_reseponse = [0, 1, 2, 3, 1, 4, 5]\n",
    "\n",
    "dummy_user = MoodAppUser(0, user_reseponse)\n",
    "\n",
    "# roughly how the feature vectors are generated.\n",
    "frequencies = Counter(user_reseponse)\n",
    "feature_vector = [round(count / len(user_reseponse), 4) for count in frequencies.values()] # NOTE : we round feature values to 4dp.\n",
    "feature_vector.append(0.0) # just to account for no \"I'm feeling neutral response\"-- this is handled programatically in the class\n",
    "\n",
    "assert feature_vector == dummy_user.feature_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create the 10 users and give them document sets that consists of a random selection of responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_OF_DAYS_TRACKED = 21\n",
    "NO_OF_USERS = 10\n",
    "\n",
    "random_document_sets = [r.choices(KEYWORDS, k = NO_OF_DAYS_TRACKED) for _ in repeat(None, NO_OF_USERS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some users and their random document sets:\n",
      "\n",
      "User 0 and their random document set:\n",
      "[0, 0, 2, 0, 6, 0, 3, 2, 5, 1, 2, 2, 1, 0, 3, 0, 4, 0, 2, 3, 6]\n",
      "\n",
      "User 1 and their random document set:\n",
      "[0, 0, 5, 0, 6, 4, 1, 5, 5, 2, 5, 1, 4, 3, 5, 2, 2, 5, 3, 4, 4]\n",
      "\n",
      "User 2 and their random document set:\n",
      "[4, 6, 3, 4, 2, 0, 5, 1, 5, 6, 4, 1, 2, 2, 0, 3, 4, 2, 1, 0, 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users = [MoodAppUser(i, document_set) for i, document_set in enumerate(random_document_sets)]\n",
    "\n",
    "print(\"Here are some users and their random document sets:\\n\")\n",
    "for i in range(3):\n",
    "    print(f\"User {users[i].id} and their random document set:\\n{users[i].document_set}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a look at their raw feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some users and their raw feature vectors:\n",
      "\n",
      "User 0 and their raw feature vectors:\n",
      "[0.3333, 0.2381, 0.0952, 0.1429, 0.0476, 0.0952, 0.0476] of length 7\n",
      "\n",
      "User 1 and their raw feature vectors:\n",
      "[0.1429, 0.2857, 0.0476, 0.1905, 0.0952, 0.1429, 0.0952] of length 7\n",
      "\n",
      "User 2 and their raw feature vectors:\n",
      "[0.2381, 0.0952, 0.0952, 0.1905, 0.1429, 0.0952, 0.1429] of length 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are some users and their raw feature vectors:\\n\")\n",
    "for i in range(3):\n",
    "    print(f\"User {users[i].id} and their raw feature vectors:\\n{users[i].feature_vector} of length {len(users[i].feature_vector)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Secure Aggregation of Feature Vectors\n",
    "\n",
    "Now that we have users and their raw feature vectors, let's compute the target function. \n",
    "\n",
    "Since this is the first run of the protocol, we begin with uniform priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1429\n",
      "0.1429\n",
      "0.1429\n",
      "0.1429\n",
      "0.1429\n",
      "0.1429\n",
      "0.1429\n"
     ]
    }
   ],
   "source": [
    "no_of_keywords = len(KEYWORDS)\n",
    "priors_for_keywords = [round(1 / no_of_keywords, 4) for _ in repeat(None, no_of_keywords)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's calculate using the raw feature vectors what the target value is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - get vector of mean for raw feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to get the same result running SAFE. Let's see if that happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - try implementing the super class FIRST, and then see what's the best way to go about implementing the SAFE functionality into a class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Trends In Interactions Over Some Static List Of Resources\n",
    "\n",
    "A neat feature of the above protocol is that it can not only be used to detect trends in user responses to the prompt question, but also to detect trends for **interactions with a static list of resources**.\n",
    "\n",
    "We simply map the list of resources to numbers just as we did with the possible questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - try creating a super class from the original User ... that has a modified constructor and what not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested Method For Free-Form Journal Entries\n",
    "\n",
    "Here we consider how mood detection might be done not in the case where there is some pre-defined list of responses a user selects from, but rather they are allowed to journal freely about whatever comes to mind for them. There may or may not be a prompt, but what is stored as their individual document sets are plain texts which we apply some pre-processing on.\n",
    "\n",
    "These journal entries can then go through the various stages of pre-processing described in (Huth and Chaulwar, 4). There is still a pre-defined vocabulary, however this time we can make use of a richer emotional taxonomy and expand the vocabulary set $V$ that is used to generate each users primary keyword set.\n",
    "\n",
    "Let's first import the `spacy` library we'll use for preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll read in our sample journal entry file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "journal_entries = \"\"\n",
    "\n",
    "with open('sample-journal-entries.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        journal_entries += (line)\n",
    "\n",
    "print(f'These are the journal entries: \\n {journal_entries}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try pick out where the keywords are mentioned in these entries. In this case, the keywords are the emotions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add match ID \"HelloWorld\" with no callback and one pattern\n",
    "pattern = [{\"LEMMA\": {\"IN\": [\"joyful\", \"sad\", \"angry\", \"disgusted\", \"afraid\", \"neutral\", \"surprised\"]}}]\n",
    "matcher.add(\"Emotions-Identifier\", [pattern])\n",
    "\n",
    "doc = nlp(journal_entries)\n",
    "\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(start, end, span.text)\n",
    "\n",
    "# do have a way of building up a frequency of the emotions. \n",
    "\n",
    "# NOTE: this is obviously a woefully inadequate way of doing NLP though. (e.g. it counts 'angry' twice even though in the second journal entry/line it occurs in a rhetorical question. So, there's still a lot more processing to do). However, if there's something to this idea I might go ahead with it?\n",
    "\n",
    "# big limitation to address is how to capture more word variations... (sadness, joyous) seems too complex though.\n",
    "\n",
    "# some other sources: https://towardsdatascience.com/keyword-extraction-process-in-python-with-natural-language-processing-nlp-d769a9069d5c\n",
    "\n",
    "# NOTE : alternative : could preprocess words. (remove stop words, lemmatize etc.), then generate a frequency of all the worlds; filter this dictionary for the emotions; and then work based off that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# todo - take from this example code block things which would be helpful to use\n",
    "\n",
    "# Rangarajan Krishnamoorthy, 2/2/2019\n",
    "# Using neuralcoref for coreference resolution\n",
    "\n",
    "taken from: https://www.rangakrish.com/index.php/2019/02/03/coreference-resolution-using-spacy/\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_coref_lg') # TODO : see if the large coref model is the right choice.\n",
    "\n",
    "examples = [\n",
    "    u'My sister has a dog and she loves him.',\n",
    "    u'My sister has a dog and she loves him. He is cute.',\n",
    "    u'My sister has a dog and she loves her.',\n",
    "    u'My brother has a dog and he loves her.',\n",
    "    u'Mary and Julie are sisters. They love chocolates.',\n",
    "    u'John and Mary are neighbours. She admires him because he works hard.',\n",
    "    u'X and Y are neighbours. She admires him because he works hard.',\n",
    "    u'The dog chased the cat. But it escaped.',\n",
    "]\n",
    "\n",
    "def printMentions(doc):\n",
    "    print '\\nAll the \"mentions\" in the given text:'\n",
    "    for cluster in doc._.coref_clusters:\n",
    "        print cluster.mentions\n",
    "\n",
    "def printPronounReferences(doc):\n",
    "    print '\\nPronouns and their references:'\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'PRON' and token._.in_coref:\n",
    "            for cluster in token._.coref_clusters:\n",
    "                print token.text + \" => \" + cluster.main.text\n",
    "\n",
    "def processDoc(text):\n",
    "    doc = nlp(text)\n",
    "    if doc._.has_coref:\n",
    "        print \"Given text: \" + text\n",
    "        printMentions(doc)\n",
    "        printPronounReferences(doc)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processDoc(examples[8])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `spacy`'s matcher, we can match for the keywords in journal entries and create freqeuencies of them in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : create frequencies of keywords in a few user's document set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Obvious Drawbacks \n",
    "\n",
    "There are obvious drawbacks to this simple NLP pre-processing as a way of counting for the keywords available.\n",
    "\n",
    "For instance, one might have noticed that the occurrence of `angry` in two drastically different semantic contexts (once in a declarative statement and another in a rhetorical question) are both simply treated alike, added to the count.\n",
    "\n",
    "<!-- illustrate the drawback with the specific example -->\n",
    "\n",
    "\n",
    "Another drawback of these approaches generally is that flat distributions are not easily recognisable in these methods.\n",
    "\n",
    "For instance, \n",
    "\n",
    "<!-- illustrate the impact of flat distributions -->\n",
    "\n",
    "Another issue that should be addressed is how to account for the fact that users may not use the app every day. How should we encode and handle non-responses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as from above: \n",
    "POSSIBLE_RESPONSES = {\n",
    "    0: \"I'm feeling joyful!\",\n",
    "    1: \"I'm feeling angry\",\n",
    "    2: \"I'm feeling disgusted\",\n",
    "    3: \"I'm feeling fearful\",\n",
    "    4: \"I'm feeling sad...\",\n",
    "    5: \"I'm feeling surprised!\",\n",
    "    6: \"I'm feeling neutral\",\n",
    "    -1: None # no response for that day.\n",
    "}\n",
    "\n",
    "u_1 = User(0, [0, 1, 2, 3, 1, 4, 5, -1]) # 8 days of collected data\n",
    "\n",
    "# what do we do with the -1?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-venv",
   "language": "python",
   "name": "project-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
