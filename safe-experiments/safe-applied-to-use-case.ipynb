{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAFE Protocol NLP Experiments \n",
    "\n",
    "[look at this link: https://medium.com/codex/the-magical-markdown-i-bet-you-dont-know-b51f8c049773]:# (resource for markdown)\n",
    "\n",
    "This notebook contains the following contents:\n",
    "\n",
    "\n",
    "It builds on top of the other notebook where I [illustrated the bare SAFE Protocol itself](./safe-illustration.ipynb) as well as [some suggestions to make it more secure](./safe-improved.ipynb). This notebook specifically illustrates the application of SAFE to trend detection in document interactions.\n",
    "\n",
    "As with the other notebooks, much of the material here relies heavily on {cite}`SAFE`.\n",
    "\n",
    "See Section 3.4.1 of the report for elaboration on the approach being implemented here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trending Mood Detection For Survey Responses\n",
    "\n",
    "As described in the report, users respond to a prompt question like \"*How do you feel today?*\" every day for a month, and an analysis on what responses are trending is carried out every 2 weeks.\n",
    "\n",
    "When submitting a response to this question, the user picks from a pre-defined list of responses that contains strings like the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_responses = {\n",
    "    0: \"I'm feeling joyful!\",\n",
    "    1: \"I'm feeling angry\",\n",
    "    2: \"I'm feeling disgusted\",\n",
    "    3: \"I'm feeling fearful\",\n",
    "    4: \"I'm feeling sad...\",\n",
    "    5: \"I'm feeling surprised!\",\n",
    "    6: \"I'm feeling neutral\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These responses are each encoded as numbers, such that what is actually stored locally on user devices as their responses are integers from `0` to `6` corresponding to each of these answers (`0` corresponds to `I'm feeling joyful!\"`, `1` corresponds to `\"I'm feeling angry\"`, and so on...)\n",
    "\n",
    "The target computation of the Bayesian approach to secure trend detection is:\n",
    "\n",
    "$$\n",
    "p(\\text{t} \\space =\\space t|D)= \\frac {p(D|\\text{t} \\space =\\space t|)p(\\text{t} \\space =\\space t|)}{p(D)} \n",
    "$$\n",
    "\n",
    "where $t$ is some term in the keyword set $V$. \n",
    "\n",
    "The **keyword set** $V$ for our experimental setting consists of the responses themselves, since what we what to determine is a probability distribution for the various moods given the overall document set contributed by users.\n",
    "\n",
    "As discussed in their paper, calculating the marginal probablity $p(D)$ would not be privacy-preserving. The authors advise avoiding calculating it by treating it as constant. Then, the posterior likelihood $p(\\text{t} \\space =\\space t|D)$ is proportional to ${p(D|\\text{t} \\space =\\space t|)p(\\text{t} \\space =\\space t|)}$. Since we are only trying to find trending keywords (in terms of rankings), we do not need the exact value of the posterior and we can simply consider this equation:\n",
    "\n",
    "$$\n",
    "p(\\text{t} \\space =\\space t|D) \\propto {p(D|\\text{t} \\space =\\space t|)p(\\text{t} \\space =\\space t|)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Defining Our Terms\n",
    "\n",
    "In particular, we want to define the terms on the RHS : the likelihood, $p(D|\\text{t} \\space =\\space t|)$, and the prior $p(\\text{t} \\space =\\space t|)$.\n",
    "\n",
    "##### Defining The Prior\n",
    "\n",
    "For the first run of the protocol, the priors will be defined uniformly-- i.e., $\\frac{1}{d}$ where $d$ is the number of keywords in $V$.\n",
    "\n",
    "For each subsequent run, the priors will be defined according to last round's posterior probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining the Likelihood Vector\n",
    "\n",
    "Let's suppose there are $N$ users who respond to the prompt question every day for $y$ days. (We assume that users respond every day with some response)\n",
    "\n",
    "This will mean that each user has a list of $y$ integer responses that represents the option they picked for each day. \n",
    "\n",
    "This will constitute their **document set** $D_{i}$ which we wish remains private, where *each integer* (representing a response) is a **document**.\n",
    "\n",
    "Each document's **primary keyword set** is simply a single-element set with the integer that represents the response they picked. (e.g. the primary keyword set of the document `1` just is `1`).\n",
    "\n",
    "As described in the paper, what ends up being the user's raw feature vector is a vector of likelihoods,\n",
    "\n",
    "$$\n",
    "L_{i}  =(p( D_ {i}  |\\text{t} \\space =\\space t_ {1}  ), \\cdots  ,p(  D_ {i}  |\\text{t} \\space =\\space t_ {d}  ))\n",
    "$$\n",
    "\n",
    "where $d$ is the number of words in the vocabulary $V$, and each $p(D_{i} | \\text{t} \\space =\\space t)$ is calculated by the fraction of the given keyword in the document set of the user.\n",
    "\n",
    "For instance, say that a user has the following document set of just 7 responses (for simplicity):\n",
    "\n",
    "```\n",
    "u_1 = [0, 1, 2, ,3, 1, 4, 5]  \n",
    "```\n",
    "\n",
    "They have 7 documents in total. Their feature vector of likelihoods is\n",
    "\n",
    "```\n",
    "V = [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "u_1 = [0, 1, 2, 3, 1, 4, 5]  \n",
    "\n",
    "u_1_feature_vector = [1/7, 2/7, 1/7, 1/7, 1/7,  1/7, 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing The Target Function\n",
    "\n",
    "Treating each user's document set $D_i$ as a random variable for the subset of the overall document set $D$ (i.e., the set of all user responses), then we can treat the aggregation of these instances (i.e., the likelihood of the whole document set) can be represented as the mean. (ibid., 5)\n",
    "\n",
    "So, the aggregator wants to compute the following for each keyword.\n",
    "\n",
    "$$\n",
    "p(D | \\text{t} \\space =\\space t_1) = \\sum_{i = 1}^N {p(D|\\text{t} \\space =\\space t_1|)}\n",
    "$$\n",
    "\n",
    "Aggregating the feature vectors for all users can be done securely using the SAFE Protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run : With Raw SAFE version\n",
    "\n",
    "Let's say there are 10 users who respond to the prompt question every day for 21 days, and as analysts we want to consider what responses are trending given this period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MoodAppUser import MoodAppUser\n",
    "\n",
    "# as from above: \n",
    "POSSIBLE_RESPONSES = {\n",
    "    0: \"I'm feeling joyful!\",\n",
    "    1: \"I'm feeling angry\",\n",
    "    2: \"I'm feeling disgusted\",\n",
    "    3: \"I'm feeling fearful\",\n",
    "    4: \"I'm feeling sad...\",\n",
    "    5: \"I'm feeling surprised!\",\n",
    "    6: \"I'm feeling neutral\",\n",
    "}\n",
    "\n",
    "# e.g. SANITY CHECK\n",
    "KEYWORDS = [0, 1, 2, 3, 4, 5, 6] # corresponding to our 7-emotion taxonomy\n",
    "\n",
    "u_1 = MoodAppUser(0, [0, 1, 2, 3, 1, 4, 5])\n",
    "\n",
    "u_1_feature_vector = [1/7, 2/7, 1/7, 1/7, 1/7,  1/7, 0] # expected\n",
    "\n",
    "assert u_1.feature_vector == u_1_feature_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested Method For Free-Form Journal Entries\n",
    "\n",
    "Here we consider how mood detection might be done not in the case where there is some pre-defined list of responses a user selects from, but rather they are allowed to journal freely about whatever comes to mind for them. There may or may not be a prompt, but what is stored as their individual document sets are plain texts which we apply some pre-processing on.\n",
    "\n",
    "These journal entries can then go through the various stages of pre-processing described in (Huth and Chaulwar, 4). There is still a pre-defined vocabulary, however this time we can make use of a richer emotional taxonomy and expand the vocabulary set $V$ that is used to generate each users primary keyword set.\n",
    "\n",
    "Let's first import the `spacy` library we'll use for preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll read in our sample journal entry file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "journal_entries = \"\"\n",
    "\n",
    "with open('sample-journal-entries.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        journal_entries += (line)\n",
    "\n",
    "print(f'These are the journal entries: \\n {journal_entries}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try pick out where the keywords are mentioned in these entries. In this case, the keywords are the emotions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add match ID \"HelloWorld\" with no callback and one pattern\n",
    "pattern = [{\"LEMMA\": {\"IN\": [\"joyful\", \"sad\", \"angry\", \"disgusted\", \"afraid\", \"neutral\", \"surprised\"]}}]\n",
    "matcher.add(\"Emotions-Identifier\", [pattern])\n",
    "\n",
    "doc = nlp(journal_entries)\n",
    "\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(start, end, span.text)\n",
    "\n",
    "# do have a way of building up a frequency of the emotions. \n",
    "\n",
    "# NOTE: this is obviously a woefully inadequate way of doing NLP though. (e.g. it counts 'angry' twice even though in the second journal entry/line it occurs in a rhetorical question. So, there's still a lot more processing to do). However, if there's something to this idea I might go ahead with it?\n",
    "\n",
    "# big limitation to address is how to capture more word variations... (sadness, joyous) seems too complex though.\n",
    "\n",
    "# some other sources: https://towardsdatascience.com/keyword-extraction-process-in-python-with-natural-language-processing-nlp-d769a9069d5c\n",
    "\n",
    "# NOTE : alternative : could preprocess words. (remove stop words, lemmatize etc.), then generate a frequency of all the worlds; filter this dictionary for the emotions; and then work based off that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# todo - take from this example code block things which would be helpful to use\n",
    "\n",
    "# Rangarajan Krishnamoorthy, 2/2/2019\n",
    "# Using neuralcoref for coreference resolution\n",
    "\n",
    "taken from: https://www.rangakrish.com/index.php/2019/02/03/coreference-resolution-using-spacy/\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_coref_lg') # TODO : see if the large coref model is the right choice.\n",
    "\n",
    "examples = [\n",
    "    u'My sister has a dog and she loves him.',\n",
    "    u'My sister has a dog and she loves him. He is cute.',\n",
    "    u'My sister has a dog and she loves her.',\n",
    "    u'My brother has a dog and he loves her.',\n",
    "    u'Mary and Julie are sisters. They love chocolates.',\n",
    "    u'John and Mary are neighbours. She admires him because he works hard.',\n",
    "    u'X and Y are neighbours. She admires him because he works hard.',\n",
    "    u'The dog chased the cat. But it escaped.',\n",
    "]\n",
    "\n",
    "def printMentions(doc):\n",
    "    print '\\nAll the \"mentions\" in the given text:'\n",
    "    for cluster in doc._.coref_clusters:\n",
    "        print cluster.mentions\n",
    "\n",
    "def printPronounReferences(doc):\n",
    "    print '\\nPronouns and their references:'\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'PRON' and token._.in_coref:\n",
    "            for cluster in token._.coref_clusters:\n",
    "                print token.text + \" => \" + cluster.main.text\n",
    "\n",
    "def processDoc(text):\n",
    "    doc = nlp(text)\n",
    "    if doc._.has_coref:\n",
    "        print \"Given text: \" + text\n",
    "        printMentions(doc)\n",
    "        printPronounReferences(doc)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processDoc(examples[8])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `spacy`'s matcher, we can match for the keywords in journal entries and create freqeuencies of them in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : create frequencies of keywords in a few user's document set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Obvious Drawbacks \n",
    "\n",
    "There are obvious drawbacks to this simple NLP pre-processing as a way of counting for the keywords available.\n",
    "\n",
    "For instance, one might have noticed that the occurrence of `angry` in two drastically different semantic contexts (once in a declarative statement and another in a rhetorical question) are both simply treated alike, added to the count.\n",
    "\n",
    "<!-- illustrate the drawback with the specific example -->\n",
    "\n",
    "\n",
    "Another drawback of these approaches generally is that flat distributions are not easily recognisable in these methods.\n",
    "\n",
    "For instance, \n",
    "\n",
    "<!-- illustrate the impact of flat distributions -->\n",
    "\n",
    "Another issue that should be addressed is how to account for the fact that users may not use the app every day. How should we encode and handle non-responses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as from above: \n",
    "POSSIBLE_RESPONSES = {\n",
    "    0: \"I'm feeling joyful!\",\n",
    "    1: \"I'm feeling angry\",\n",
    "    2: \"I'm feeling disgusted\",\n",
    "    3: \"I'm feeling fearful\",\n",
    "    4: \"I'm feeling sad...\",\n",
    "    5: \"I'm feeling surprised!\",\n",
    "    6: \"I'm feeling neutral\",\n",
    "    -1: None # no response for that day.\n",
    "}\n",
    "\n",
    "u_1 = User(0, [0, 1, 2, 3, 1, 4, 5, -1]) # 8 days of collected data\n",
    "\n",
    "# what do we do with the -1?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
