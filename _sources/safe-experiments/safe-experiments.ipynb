{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments Using The SAFE Protocol\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This notebook includes the experiments conducted using the SAFE Protocol. The goal was to assess the suitability of the SAFE Protocol for meeting the privacy and utility constraints outlined in the introduction of the report, as well as consider possible extensions.\n",
    "\n",
    "The notebook has the following contents:\n",
    "- Toy Implementation Of SAFE (How SAFE works)\n",
    "- Evaluation of SAFE's Robustness\n",
    "- Making SAFE more robust.\n",
    "\n",
    "[make this a proper TOC with links]: # (add links to the above)\n",
    "\n",
    "The Toy implementation of SAFE is merely illustrative-- mock data of a small size will be used to illustrate the basic mechanics of the SAFE protocol.\n",
    "\n",
    "### Setting Up Toy Implementation\n",
    "\n",
    "To illustrate how the SAFE Protocol works, we will mock the data of 5 users who contribute feature vectors. \n",
    "\n",
    "#### Set Up Raw Vector Creation\n",
    "\n",
    "First, let's create the raw feature vectors for each user. These vectors represent the raw data the SAFE protocol wants to keep private whilst allowing for useful computation over.\n",
    "\n",
    "[add more explanation]: # (explain what the vectors are)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are is the feature vector for user 0: \n",
      "tensor([[0.4963],\n",
      "        [0.7682]])\n",
      "\n",
      "\n",
      "Here are is the feature vector for user 1: \n",
      "tensor([[0.0885],\n",
      "        [0.1320]])\n",
      "\n",
      "\n",
      "Here are is the feature vector for user 2: \n",
      "tensor([[0.3074],\n",
      "        [0.6341]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SET UP - Create raw feature vectors \n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "    # for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "    # CONSTANTS for a run of the Protocol\n",
    "NUMBER_OF_USERS = 3\n",
    "NUMBER_OF_FEATURES_PER_USER_VECTOR = 2\n",
    "VECTOR_SHAPE = (NUMBER_OF_FEATURES_PER_USER_VECTOR, 1)\n",
    "# TODO: actually, VECTOR_SHAPE is redundant. That wasn't the source of the error. But, anyways.\n",
    " \n",
    "raw_feature_vectors = {}\n",
    "\n",
    "for i in range(NUMBER_OF_USERS):\n",
    "    raw_feature_vectors[i] = torch.rand(VECTOR_SHAPE)\n",
    "    print(f\"Here are is the feature vector for user {i}: \")\n",
    "    print(raw_feature_vectors[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHARE CREATION AND DISTRIBUTION\n",
    "\n",
    "Next, each user will generate (N-1) shares from the interval [-D, D], where N is the number of users. \n",
    "\n",
    "Each share is a K-dimensional vector, where K is the number of features each user's raw feature vector has.\n",
    "\n",
    "Each user uses these N-1 shares to generate their own Nth share. \n",
    "\n",
    "Then, they will distribute the N-1 shares to the other N-1 users, whilst keeping their Nth share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the shares for each user \n",
      "\n",
      "Let's take a look at shares each user will distribute:\n",
      "\n",
      "User 0: \n",
      "\n",
      "tensor([[6.8884],\n",
      "        [5.1591]])\n",
      "tensor([[-1.5886],\n",
      "        [-4.8217]])\n",
      "\n",
      "\n",
      "And here's their Nth share:\n",
      "\n",
      "tensor([[-4.8036],\n",
      "        [ 0.4308]])\n",
      "\n",
      "\n",
      "User 1: \n",
      "\n",
      "tensor([[ 0.2255],\n",
      "        [-1.9013]])\n",
      "tensor([[ 5.6760],\n",
      "        [-3.9337]])\n",
      "\n",
      "\n",
      "And here's their Nth share:\n",
      "\n",
      "tensor([[-5.8130],\n",
      "        [ 5.9671]])\n",
      "\n",
      "\n",
      "User 2: \n",
      "\n",
      "tensor([[-0.4681],\n",
      "        [ 1.6676]])\n",
      "tensor([[8.1623],\n",
      "        [0.0937]])\n",
      "\n",
      "\n",
      "And here's their Nth share:\n",
      "\n",
      "tensor([[-7.3868],\n",
      "        [-1.1273]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SHARE CREATION\n",
    "\n",
    "import random\n",
    "from token import NUMBER\n",
    "from unicodedata import name\n",
    "\n",
    "from numpy import shares_memory \n",
    "random.seed(0)\n",
    "\n",
    "D_VALUE = 10.0 # defining the interval from which users drawn random share vectors.\n",
    "\n",
    "print(\"Generating the shares for each user \\n\")\n",
    "each_users_shares_to_distribute = {} # mapping from i to list of tensors.\n",
    "each_users_Nth_share = {} # mapping from i to 4-D tensor\n",
    "for user in range(NUMBER_OF_USERS):\n",
    "    # Each user first generates N-1 shares : a share to be sent to every other user.\n",
    "    each_users_shares_to_distribute[user] = []\n",
    "    for other_user in range(NUMBER_OF_USERS - 1):\n",
    "        share_to_distribute = [random.uniform(-D_VALUE, D_VALUE) for i in range(NUMBER_OF_FEATURES_PER_USER_VECTOR)]\n",
    "        share_to_distribute = torch.reshape(torch.tensor(share_to_distribute), VECTOR_SHAPE)\n",
    "        each_users_shares_to_distribute[user].append(share_to_distribute)\n",
    "    # Then, each user calculates their own Nth share from the N-1 Shares the draw from the interval\n",
    "    sum_of_shares = torch.zeros(VECTOR_SHAPE)\n",
    "    for share in each_users_shares_to_distribute[user]:\n",
    "        sum_of_shares.add_(share)\n",
    "    # print(f\"Here is user_{user}'s sum of shares: {sum_of_shares}\")\n",
    "    each_users_Nth_share[user] = raw_feature_vectors[user] - sum_of_shares \n",
    "\"\"\"\n",
    "TODO:\n",
    "Not sure whether there's a better way to generate the shares. The calls to the random.uniform() method for each share vector value seems sub-optimal but I can't quite find an 'off-the-shelf' method that generates the matrix/dictionary more easily. This triple nested loop is not computationally efficient. Is commenting on the algorithm's time complexity worth doing?\n",
    "\n",
    "TODO: \n",
    "Also not sure whether the 'random' provided by Python is sufficiently random. Or whether the presence of a 'seed' value complicates things.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Let's take a look at shares each user will distribute:\\n\")\n",
    "for user in range(NUMBER_OF_USERS):\n",
    "    print(f\"User {user}: \\n\")\n",
    "    for share in each_users_shares_to_distribute[user]:\n",
    "        print(share)\n",
    "    print(\"\\n\")    \n",
    "    print(\"And here's their Nth share:\\n\")\n",
    "    print(each_users_Nth_share[user])\n",
    "    print(\"\\n\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's distribute the shares among the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributing shares...\n",
      "\n",
      "Let's see what the first three users got:\n",
      "User_0 received:\n",
      "tensor([[ 0.2255],\n",
      "        [-1.9013]])\n",
      "tensor([[-0.4681],\n",
      "        [ 1.6676]])\n",
      "\n",
      "\n",
      "User_1 received:\n",
      "tensor([[6.8884],\n",
      "        [5.1591]])\n",
      "tensor([[8.1623],\n",
      "        [0.0937]])\n",
      "\n",
      "\n",
      "User_2 received:\n",
      "tensor([[-1.5886],\n",
      "        [-4.8217]])\n",
      "tensor([[ 5.6760],\n",
      "        [-3.9337]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SHARE Distribution\n",
    "\n",
    "print(\"Distributing shares...\\n\")\n",
    "each_users_received_shares = {}\n",
    "# set up the map\n",
    "for i in range(NUMBER_OF_USERS):\n",
    "    each_users_received_shares[i] = []\n",
    "# fill the map\n",
    "for user in range(NUMBER_OF_USERS):\n",
    "    other_user_ids = [ind for ind in range(NUMBER_OF_USERS) if ind != user]\n",
    "    # get the shares for user_0 to send to other users\n",
    "    shares_to_send = [share for share in each_users_shares_to_distribute[user]]\n",
    "    for other_user, share_to_send in zip(other_user_ids, shares_to_send):\n",
    "        each_users_received_shares[other_user].append(share_to_send)\n",
    "# TODO - add a more robust sanity check to ensure shares were sent.\n",
    "print(\"Let's see what the first three users got:\")\n",
    "for i in range(3):\n",
    "    print(f\"User_{i} received:\")\n",
    "    print(*each_users_received_shares[i], sep=\"\\n\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# sanity check\n",
    "assert len(each_users_received_shares[0]) == NUMBER_OF_USERS - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obfuscated Vector Generation\n",
    "\n",
    "Each user can now calculate their own ofuscated feature vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's what each user will send to the aggregator:\n",
      "\n",
      "User 0:\n",
      "tensor([[-5.0462],\n",
      "        [ 0.1971]])\n",
      "\n",
      "\n",
      "User 1:\n",
      "tensor([[ 9.2377],\n",
      "        [11.2199]])\n",
      "\n",
      "\n",
      "User 2:\n",
      "tensor([[-3.2994],\n",
      "        [-9.8827]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GENERATING OBFUSCATED FEATURE Vectors:\n",
    "\"\"\"\n",
    "each_users_masked_vector = {}\n",
    "\n",
    "for user in range(NUMBER_OF_USERS):\n",
    "    sum_of_received_shares = torch.zeros(VECTOR_SHAPE)\n",
    "    for share in each_users_received_shares[user]:\n",
    "        sum_of_received_shares.add_(share)\n",
    "    each_users_masked_vector[user] = each_users_Nth_share[user] + sum_of_received_shares \n",
    "\n",
    "print(\"Here's what each user will send to the aggregator:\\n\")\n",
    "for user, masked_vector in each_users_masked_vector.items():\n",
    "    print(f\"User {user}:\")\n",
    "    print(masked_vector)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating Feature Vectors\n",
    "\n",
    "Now we will mock an aggregator who receives each feature vector and computes a target function. In the actual protocol, each user would 'send' their masked vector to an aggregator. For simplicity's sake, we will simply act as an aggregator that has already received these vectors, and simply compute the target function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of masked vectors: \n",
      "\n",
      " tensor([[0.8922],\n",
      "        [1.5343]])\n",
      "\n",
      "Sum of raw vectors: \n",
      "\n",
      " tensor([[0.8922],\n",
      "        [1.5343]])\n"
     ]
    }
   ],
   "source": [
    "# Computing Target Function: Aggregate Sum\n",
    "\n",
    "target_result = sum(raw_feature_vectors[user] for user in raw_feature_vectors.keys())\n",
    "\n",
    "masked_vector_result = sum(each_users_masked_vector[user] for user in each_users_masked_vector.keys())\n",
    "\n",
    "print(f\"Sum of masked vectors: \\n\\n {masked_vector_result}\\n\")\n",
    "print(f\"Sum of raw vectors: \\n\\n {target_result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility of Protocol\n",
    "\n",
    "As the output from the code block above shows, the aggregate sum of the masked vectors is equivalent to the aggregate sum of the raw vectors of the users. \n",
    "\n",
    "Also, it follows from this that simple mean of both vector sets are equal as well. \n",
    "\n",
    "SAFE thus does allow one to compute some aggregate functions over user data without having direct access to the user data. \n",
    "\n",
    "However, let us now consider how robustly it masks the raw feature vectors from potential adversaries who would try to infer things about the raw data from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating SAFE's Robustness\n",
    "\n",
    "We will consider this in terms of the information flow that the protocol allows from, and from the perspective of an adversarial aggregator, and an adversarial set of user(s). \n",
    "\n",
    "#### Adversarial Aggregator\n",
    "\n",
    "We will assume that the aggregator knows what is presented plainly in Huth and Chuartwal's paper i.e., the equations listed in Section 4. Moreover, as described in the Protocol, the aggregator receives from each user an obfuscated feature vector. Finally, let us assume that the aggregator knows the values of the interval [-D, D] from which the users compute their share vectors. \n",
    "\n",
    "We want to ascertain what such an aggregator could infer from what they know. \n",
    "\n",
    "<!--Let us consider an even simpler example than the one we ran above: each user's raw feature vector is just one dimension.\n",
    "\n",
    "Let `x` represent the `user_x`'s raw vector. Recall that, the value of a user's feature vectors are within the interval `[0,1]`, representing probabilities. So, let the value in `x` = 0.3. \n",
    "\n",
    "The aggregator knows the interval the users draws from is, as in our toy run,  `[-10, 10]`. \n",
    "\n",
    "Now, suppose the aggregator draws a random share from this interval, `y` , and `y` = -5.7.\n",
    "\n",
    "Additionally, the aggregator receives an obfuscated vector `x'` from `user_x` , and `x'` = -5.4.-->\n",
    "\n",
    "Suppose the adversarial aggregator drew their own N-1 shares from the same `[-D, D]` distribution. They could try to make an educated guess about the distribution of the raw feature values through reverse engineering:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(0, tensor([[-0.3114],\n",
      "        [-9.7826]])), (1, tensor([[13.9725],\n",
      "        [ 1.2402]])), (2, tensor([[  1.4354],\n",
      "        [-19.8625]]))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38923/2521218717.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  share = torch.reshape(torch.tensor(share_to_distribute), VECTOR_SHAPE)\n"
     ]
    }
   ],
   "source": [
    "# Aggregator samples (N-1) Random shares for each user.\n",
    "\n",
    "aggregators_random_shares_per_user = {}\n",
    "for user in range(NUMBER_OF_USERS):\n",
    "    aggregators_random_shares_per_user[user] = []\n",
    "    for i in range(NUMBER_OF_USERS - 1):\n",
    "        share = [random.uniform(-D_VALUE, D_VALUE) for i in range(NUMBER_OF_FEATURES_PER_USER_VECTOR)]\n",
    "        share = torch.reshape(torch.tensor(share_to_distribute), VECTOR_SHAPE)\n",
    "        aggregators_random_shares_per_user[user].append(share)\n",
    "\n",
    "received_masked_vectors = each_users_masked_vector\n",
    "\n",
    "# Minus the Sum of the N-1 Shares From The Masked Vectors To Approximate Nth Share\n",
    "\n",
    "approximation_of_each_users_Nth_share = {}\n",
    "\n",
    "for user in range(NUMBER_OF_USERS):\n",
    "    sum_of_aggregators_random_shares = torch.zeros(VECTOR_SHAPE)\n",
    "    for v in aggregators_random_shares_per_user[user]:\n",
    "        sum_of_aggregators_random_shares.add_(v)\n",
    "    approximation_of_each_users_Nth_share[user] =  received_masked_vectors[user] - sum_of_aggregators_random_shares\n",
    "\n",
    "print(approximation_of_each_users_Nth_share.items()) \n",
    "\n",
    "# Minus the Sum of the N-1 Shares Again From Approximation : TODO why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Protocol More Secure\n",
    "\n",
    "Here, we illustrate the use of Homomorphic Encryption to make the protocol even more secure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAdjusting Feature Value Representation\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Adjusting Feature Value Representation\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "my_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
